# シーケンス図

アプリにおける主な処理フローは以下のとおりです。

![シーケンス図]

## 全体フロー

1. **ユーザー操作**

   * テキスト入力 or 音声録音を開始／停止
2. **クライアント → API**

   * テキスト分析: `POST /diary` に `uid`, `date`, `text` を FormData で送信
   * 音声分析: `POST /diary/audio` に `uid`, `date`, `audio` ファイルを multipart で送信
3. **FastAPI サーバー（Cloud Run）受信**

   * リクエストを受け取り、パラメータ／ファイルを取得
4. **音声 → 文字起こし**（音声送信時のみ）

   * Google Cloud Speech-to-Text API でバイト列を文字化
5. **感情解析 & 配色生成**

   * 文字列を Vertex AI（Gemini）に投げ、
   * レスポンスから (x, y) 座標とカラーコードをパース
6. **Firestore 書き込み**

   * `BackgroundTasks` で非同期にドキュメントを保存
   * ドキュメントID: `{uid}_{date}`
7. **API → クライアント**

   * JSON レスポンスで `x`, `y`, `color` を返却
8. **クライアント表示**

   * 受け取ったカラーを UI に反映、ユーザーが結果を確認

## テキスト結果の編集フロー

1. ユーザーが解析結果テキストを編集
2. 修正テキストを別エンドポイント（例: `POST /diary/text`）に送信
3. API で再解析し、Firestore ドキュメントを更新
4. 更新済み結果をクライアントに返却

---

以上が、音声／テキスト両対応の感情解析アプリにおけるエンドツーエンドのシーケンスと処理概要です。
